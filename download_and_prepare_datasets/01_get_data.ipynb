{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233d3d37",
   "metadata": {},
   "source": [
    "# Download Primary and Secondary Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b165354",
   "metadata": {},
   "source": [
    "The primary dataset comprises eight months (Mayâ€“December, 2019) of flight and weather data from US airports from the [Historical Flight Delay and Weather Data USA](https://www.kaggle.com/datasets/ioanagheorghiu/historical-flight-and-weather-data) dataset on [Kaggle](https://www.kaggle.com/).\n",
    "\n",
    "The data was originally sourced from the [United States Bureau of Transportation Statistics](https://www.bts.gov/browse-statistical-products-and-data/bts-publications/airline-service-quality-performance-234-time) and the [National Oceanic and Atmospheric Administration](https://www.ncdc.noaa.gov/cdo-web/datatools/lcd).\n",
    "\n",
    "<hr>\n",
    "\n",
    "The secondary dataset comes from [The Global Airport Database](https://www.partow.net/miscellaneous/airportdatabase/index.html). It contains a list of airport codes along with their three-dimensional geographic coordinates (latitude, longitide, and altitude).\n",
    "\n",
    "The data types for its columns (useful for setting up a database schema) can be found at the link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5d887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasources = {\n",
    "    # Primary dataset; format: Kaggle USERNAME/DATASET\n",
    "    \"primary\" : 'ioanagheorghiu/historical-flight-and-weather-data',\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "# Primary dataset; format: Kaggle USERNAME/DATASET\n",
    "datasource_primary = 'ioanagheorghiu/historical-flight-and-weather-data'\n",
    "\n",
    "# Seconday dataset; format: URL\n",
    "datasource_secondary = 'https://www.partow.net/downloads/GlobalAirportDatabase.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2020bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c74587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the necessary folder structure exists, and make `resources` the working directory\n",
    "os.chdir('..')\n",
    "os.makedirs('resources',exist_ok=True)\n",
    "os.chdir('resources')\n",
    "data_dir = os.path.join('.','data')\n",
    "for d in ['config',data_dir,'images']:\n",
    "    os.makedirs(d,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb9930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths to downloaded datasets\n",
    "dataset_primary = os.path.join(data_dir,os.path.basename(datasource_primary) + '.zip')\n",
    "dataset_secondary = os.path.join(data_dir,os.path.basename(datasource_secondary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f66784",
   "metadata": {},
   "source": [
    "### Install Kaggle API.\n",
    "\n",
    "If you do not already have the Kaggle API installed, **enable the cell below** by converting it to Cell Type `Code`. (In the Jupyter Notebook menus, select `Cell` > `Cell Type` > `Code`.) Then, go to https://www.kaggle.com/docs/api and follow the `Authentication` instructions.\n",
    "\n",
    "Additional details about how to use the Kaggle API with Jupyter Notebook can be found [here](https://www.kaggle.com/code/donkeys/kaggle-python-api/notebook), [here](https://technowhisp.com/kaggle-api-python-documentation/), or [here](https://stackoverflow.com/a/60309843).\n",
    "\n",
    "### Important\n",
    "Your `kaggle.json` API key file must be in the proper location as specified in the `Authentication` instructions above."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca3f9816",
   "metadata": {},
   "source": [
    "# %%capture\n",
    "# Uncomment the line above to suppress output\n",
    "\n",
    "!pip install kaggle\n",
    "\n",
    "# Try the command below, if the above fails on Mac/Linux\n",
    "# !pip install --user kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af4467",
   "metadata": {},
   "source": [
    "## Download Primary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da56c024",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b4562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kag = KaggleApi()\n",
    "kag.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6db4921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "# Download primary dataset from Kaggle\n",
    "kag.dataset_download_files(\n",
    "    dataset=datasource_primary,\n",
    "#     unzip=True,\n",
    "    path=data_dir,\n",
    ")\n",
    "\n",
    "print('Download complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5e850",
   "metadata": {},
   "source": [
    "## Download Secondary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2900b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360c1709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "# Download the secondary datasets\n",
    "response = requests.get(datasource_secondary)\n",
    "\n",
    "try:\n",
    "    with open(dataset_secondary, 'xb') as dl_file:\n",
    "        for chunk in response.iter_content(chunk_size=128):\n",
    "            dl_file.write(chunk)\n",
    "        print('Download complete.')\n",
    "except FileExistsError:\n",
    "    print('Download complete. (File already exists.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22632d",
   "metadata": {},
   "source": [
    "## UnZip Downloaded Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d0fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4bba833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "for dataset in [dataset_primary,dataset_secondary]:\n",
    "    with zipfile.ZipFile(dataset, 'r') as data_zip:\n",
    "        # Extract only files that do not already exist\n",
    "        member_list = (set(data_zip.namelist()) - set(os.listdir(data_dir)))\n",
    "        data_zip.extractall(data_dir, members=member_list)\n",
    "print('Extraction complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306af33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
